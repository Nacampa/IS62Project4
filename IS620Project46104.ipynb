{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load assignment12v41.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IS620 - Assignment 12 (6.10.4)\n",
      "# Program: assignment12.py\n",
      "# Student: Neil Acampa\n",
      "# Date:    10/31/16\n",
      "# Function:\n",
      "\n",
      "\n",
      "\n",
      "#    6.10.4 \n",
      "#    Using movie reviews: Display and analyze the top 30 features\n",
      "\n",
      "\n",
      "\n",
      "from __future__ import absolute_import \n",
      "from __future__ import division\n",
      "import re\n",
      "import os \n",
      "import math\n",
      "import decimal\n",
      "import numpy as np\n",
      "import scipy\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from pandas import DataFrame\n",
      "import networkx as nx\n",
      "import random\n",
      "from urllib import urlopen\n",
      "import nltk\n",
      "nltk.download('gutenberg')\n",
      "from nltk import word_tokenize\n",
      "nltk.download('maxent_treebank_pos_tagger')\n",
      "nltk.download('punkt')\n",
      "nltk.download('movie_reviews')\n",
      "nltk.download('stopwords')\n",
      "tokenizer = nltk.data.load('nltk:tokenizers/punkt/english.pickle')\n",
      "from nltk.corpus import movie_reviews\n",
      "from nltk.corpus import stopwords\n",
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "\n",
      "linelst=[]\n",
      "lines  = \"\"\n",
      "allwords          = []   # Contains all words\n",
      " \n",
      "\n",
      "dindx             = 0    # Document index\n",
      "\n",
      "\n",
      "masterdict        = []\n",
      "masterdictcnt     = []\n",
      "masterdictcntpos  = []\n",
      "masterdictcntneg  = []\n",
      "masterdictcat     = []\n",
      "# Table Elements\n",
      "\n",
      "fheadings      = [] \n",
      "\n",
      "fheadings.append(\"Words w/o stopwords - Train on 100-2000, Test on first 100\")\n",
      "fheadings.append(\"Words w/0 stopwords - Train on 90%, Test on first 1       \")\n",
      "\n",
      "\n",
      "rejectchars = [',','.','?','<','>','!','\"','-','%','&','#','(',')','*',';'];\n",
      "rcnt = len(rejectchars);\n",
      "\n",
      "\n",
      "def remove_characters(word):\n",
      "  \"\"\"Replace special characters in the word\"\"\"\n",
      "  \n",
      "  for i in range(rcnt):\n",
      "    rchar = rejectchars[i]\n",
      "    if rchar in word:\n",
      "      word = word.replace(rchar,\"\")\n",
      "\n",
      "  return word\n",
      "\n",
      "\n",
      "def remove_symbols(word):\n",
      "  \"\"\"Replace symbols in the word\"\"\"\n",
      "  w = len(word)\n",
      "  word = (ord(c) for c in word) \n",
      "  word = map(lambda x:x if x<123 or x>255 else \" \", word)\n",
      "  newword=\"\"\n",
      "  for c in range(w):\n",
      "    if word[c] <> \" \":\n",
      "      newword += chr(word[c]);\n",
      "  \n",
      "  return newword\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def document_features(document):\n",
      "  docwords = set(document)\n",
      "  features = {}\n",
      "  for word in wordfeatures:\n",
      "    features['contains(%s)' % word] = (word in docwords)\n",
      " \n",
      "  return features\n",
      "\n",
      "\n",
      "def document_features_all(document):\n",
      "  docwords = set(document)\n",
      "  features = {}\n",
      "  for word in wordfeaturesall:\n",
      "    features['contains(%s)' % word] = (word in docwords)\n",
      " \n",
      "  return features\n",
      "\n",
      "\n",
      "\n",
      "filepath=\"\"\n",
      "temp    =\"\"\n",
      "tokens  = \"\"\n",
      "valid   = 0\n",
      "p       = 1\n",
      "cwd = os.getcwd()\n",
      "print\n",
      "print\n",
      "print(\"Getting Movie Review words\")\n",
      "results = []\n",
      "documents = [(list(movie_reviews.words(fileid)), category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)]\n",
      "random.shuffle(documents)\n",
      "dl = len(documents)\n",
      "\n",
      "print\n",
      "print(\"Getting top 2000 most frequent movie review words subtracting Stopwords\")\n",
      "# Top most frequent words in movie reviews without stopwords\n",
      "fd              = nltk.FreqDist(w.lower() for w in movie_reviews.words() if w.lower() not in stopwords)\n",
      "wordfeatures    = fd.keys()[:2000]\n",
      "\n",
      "\n",
      "\n",
      "# Features Positive/Negative with stop words removed\n",
      "print\n",
      "print(\"Processing Features without stopwords\")\n",
      "print(\"Training from Document 100 to 2000, Testing on the first 100\")\n",
      "print\n",
      "featuresets=[]\n",
      "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
      "train_set, test_set  = featuresets[100:], featuresets[:100]\n",
      "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "accuracy   = nltk.classify.accuracy(classifier, test_set)\n",
      "results.append(accuracy)\n",
      "print\n",
      "print(classifier.show_most_informative_features(30))\n",
      "\n",
      "# Features Positive/Negative with stop words removed\n",
      "print\n",
      "print(\"Processing Features without stop words\")\n",
      "print(\"Training on 90 percent, Testing on 10 percent\")\n",
      "print\n",
      "# Train on 90%, Test on 10%\n",
      "featuresets = []\n",
      "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
      "fcnt = len(featuresets)\n",
      "testlim  = int(fcnt*.10)\n",
      "trainlim = testlim +1\n",
      "train_set, test_set  = featuresets[trainlim:], featuresets[:testlim]\n",
      "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "accuracy   = nltk.classify.accuracy(classifier, test_set)\n",
      "results.append(accuracy)\n",
      "print\n",
      "print(classifier.show_most_informative_features(30))\n",
      "\n",
      "print\n",
      "print\n",
      "print\n",
      "l = len(results)\n",
      "print (\"%s\\t%s\\t%s\") % (\"Feature\" , \"Feature Desc                              \", \"                Accuracy\")\n",
      "indx = 0\n",
      "for i in range(l):\n",
      "  indx = indx + 1\n",
      "  print(\"%d\\t%s\\t%.4f\") % (indx, fheadings[i], results[i])\n",
      "\n",
      "\n",
      "print\n",
      "print\n",
      "print\n",
      "print(\"A neg/pos value of 7.7:1.0 for the word 'mediocrity' means\")\n",
      "print(\"We are 7.7 times more likely to see 'mediocrity' in documents classified\")\n",
      "print(\"with a negative review\")\n",
      "print\n",
      "print(\"This is not suprising since there is a negative\")\n",
      "print(\"connotation associated with a movie or performance that is average\")\n",
      "print\n",
      "print(\"A pos/neg value of 7.7:1.0 for the word 'hugo' means\")\n",
      "print(\"we are 7.7 times more likely to see 'hugo' in documents classified\")\n",
      "print(\"with a positive review\")\n",
      "print\n",
      "print(\"This is  also not suprising if the rating is referencing\")\n",
      "print(\"the movie 'Hugo' which was in my option excellent\")\n",
      "print\n",
      "print(\"A pos/neg value of 6.3:1.0 for the word 'overwhelmed' means\")\n",
      "print(\"we are 6.3 times more likely to see 'overwhelmed' in documents classified\")\n",
      "print(\"with a positive review\")\n",
      "print\n",
      "print(\"This is also not suprising since 'overwhelmed' is often followed with joy, with happyness\")\n",
      "print(\"but depending on the context 'overwhelmed' can indicate a negative setiment\")\n",
      "print\n",
      "print(\"A pos/neg value of 5.7:1.0 for the word 'dismissed' means\")\n",
      "print(\"we are 5.7 times more likely to see 'dismissed' in documents classified\")\n",
      "print(\"with a positive review\")\n",
      "print\n",
      "print(\"This is suprising since 'dismissed' in some contexts\")\n",
      "print(\"has a negative connotation\")\n",
      "print(\"Dismissed from a position, dismissed the story as..\")\n",
      "print\n",
      "print(\"A neg/pos value of 3.7:1.0 for the word 'derivative' means\")\n",
      "print(\"we are 3.7 times more likely to see 'derivative' in documents classified\")\n",
      "print(\"with a negative review\")\n",
      "print\n",
      "print(\"This is not surprising since the word is found in movie review\")\n",
      "print(\"In this context, the word implies that the film (plot, cinematography), the acting or directing\")\n",
      "print(\"may be very similar to anothers or that it lacks originality\")\n",
      "print(\"In a mathematical context, 'derivative' would be neutral\")\n",
      "print\n",
      "print(\"A neg/pos value of 5.0:1.0 for the word 'ugh' means\")\n",
      "print(\"we are 5.0 times more likely to see 'ugh' in documents classified\")\n",
      "print(\"with a negative review\")\n",
      "print\n",
      "print(\"This is not surprising at all since 'ugh' says it all\")\n",
      "print\n",
      "print(\"For many reviews, without fully knowing the context of the word in the sentence\")\n",
      "print(\"it is very difficult to determine if the classification is correct\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run assignment12v41.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package gutenberg to\n",
        "[nltk_data]     C:\\Users\\nacampa\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package gutenberg is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
        "[nltk_data]     C:\\Users\\nacampa\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
        "[nltk_data]       date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[nltk_data] Downloading package punkt to\n",
        "[nltk_data]     C:\\Users\\nacampa\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package punkt is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[nltk_data] Downloading package movie_reviews to\n",
        "[nltk_data]     C:\\Users\\nacampa\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package movie_reviews is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[nltk_data] Downloading package stopwords to\n",
        "[nltk_data]     C:\\Users\\nacampa\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package stopwords is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Getting Movie Review words\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting top 2000 most frequent movie review words subtracting Stopwords\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing Features without stopwords\n",
        "Training from Document 100 to 2000, Testing on the first 100\n",
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "          contains(sans) = True              neg : pos    =      8.3 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         contains(tripe) = True              neg : pos    =      7.7 : 1.0\n",
        "    contains(mediocrity) = True              neg : pos    =      7.0 : 1.0\n",
        "     contains(dismissed) = True              pos : neg    =      7.0 : 1.0\n",
        "   contains(bruckheimer) = True              neg : pos    =      6.3 : 1.0\n",
        "        contains(fabric) = True              pos : neg    =      6.3 : 1.0\n",
        "         contains(wires) = True              neg : pos    =      6.3 : 1.0\n",
        "   contains(overwhelmed) = True              pos : neg    =      6.3 : 1.0\n",
        "     contains(uplifting) = True              pos : neg    =      6.1 : 1.0\n",
        "           contains(ugh) = True              neg : pos    =      5.8 : 1.0\n",
        "        contains(doubts) = True              pos : neg    =      5.8 : 1.0\n",
        "          contains(wits) = True              pos : neg    =      5.7 : 1.0\n",
        "       contains(topping) = True              pos : neg    =      5.7 : 1.0\n",
        "        contains(bounce) = True              neg : pos    =      5.7 : 1.0\n",
        "          contains(lang) = True              pos : neg    =      5.7 : 1.0\n",
        "      contains(recycles) = True              neg : pos    =      5.0 : 1.0\n",
        "   contains(sensational) = True              pos : neg    =      5.0 : 1.0\n",
        "  contains(effortlessly) = True              pos : neg    =      5.0 : 1.0\n",
        "          contains(hugo) = True              pos : neg    =      4.6 : 1.0\n",
        "      contains(attorney) = True              pos : neg    =      4.6 : 1.0\n",
        "       contains(morally) = True              pos : neg    =      4.3 : 1.0\n",
        "      contains(matheson) = True              pos : neg    =      4.3 : 1.0\n",
        "       contains(maxwell) = True              neg : pos    =      4.3 : 1.0\n",
        "           contains(tv2) = True              neg : pos    =      4.3 : 1.0\n",
        "      contains(goldsman) = True              neg : pos    =      4.3 : 1.0\n",
        "         contains(locks) = True              neg : pos    =      4.3 : 1.0\n",
        "          contains(wang) = True              pos : neg    =      4.3 : 1.0\n",
        "    contains(cronenberg) = True              pos : neg    =      4.2 : 1.0\n",
        "     contains(testament) = True              pos : neg    =      3.9 : 1.0\n",
        "   contains(understands) = True              pos : neg    =      3.9 : 1.0\n",
        "None\n",
        "\n",
        "Processing Features without stop words\n",
        "Training on 90 percent, Testing on 10 percent\n",
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "          contains(sans) = True              neg : pos    =      8.3 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         contains(tripe) = True              neg : pos    =      7.7 : 1.0\n",
        "     contains(dismissed) = True              pos : neg    =      7.0 : 1.0\n",
        "        contains(fabric) = True              pos : neg    =      6.3 : 1.0\n",
        "   contains(overwhelmed) = True              pos : neg    =      6.3 : 1.0\n",
        "   contains(bruckheimer) = True              neg : pos    =      6.3 : 1.0\n",
        "         contains(wires) = True              neg : pos    =      6.3 : 1.0\n",
        "     contains(uplifting) = True              pos : neg    =      6.1 : 1.0\n",
        "           contains(ugh) = True              neg : pos    =      5.8 : 1.0\n",
        "       contains(topping) = True              pos : neg    =      5.7 : 1.0\n",
        "          contains(lang) = True              pos : neg    =      5.7 : 1.0\n",
        "    contains(mediocrity) = True              neg : pos    =      5.7 : 1.0\n",
        "        contains(bounce) = True              neg : pos    =      5.7 : 1.0\n",
        "   contains(sensational) = True              pos : neg    =      5.0 : 1.0\n",
        "        contains(doubts) = True              pos : neg    =      5.0 : 1.0\n",
        "      contains(recycles) = True              neg : pos    =      5.0 : 1.0\n",
        "      contains(recycled) = True              neg : pos    =      5.0 : 1.0\n",
        "    contains(leadership) = True              pos : neg    =      4.6 : 1.0\n",
        "  contains(effortlessly) = True              pos : neg    =      4.4 : 1.0\n",
        "          contains(wits) = True              pos : neg    =      4.3 : 1.0\n",
        "       contains(morally) = True              pos : neg    =      4.3 : 1.0\n",
        "      contains(matheson) = True              pos : neg    =      4.3 : 1.0\n",
        "          contains(wang) = True              pos : neg    =      4.3 : 1.0\n",
        "       contains(maxwell) = True              neg : pos    =      4.3 : 1.0\n",
        "           contains(tv2) = True              neg : pos    =      4.3 : 1.0\n",
        "      contains(goldsman) = True              neg : pos    =      4.3 : 1.0\n",
        "         contains(locks) = True              neg : pos    =      4.3 : 1.0\n",
        "          contains(hugo) = True              pos : neg    =      4.2 : 1.0\n",
        "      contains(attorney) = True              pos : neg    =      4.1 : 1.0\n",
        "    contains(cronenberg) = True              pos : neg    =      3.8 : 1.0\n",
        "None\n",
        "\n",
        "\n",
        "\n",
        "Feature\tFeature Desc                              \t                Accuracy\n",
        "1\tWords w/o stopwords - Train on 100-2000, Test on first 100\t0.6000\n",
        "2\tWords w/0 stopwords - Train on 90%, Test on first 1       \t0.6150\n",
        "\n",
        "\n",
        "\n",
        "A neg/pos value of 7.7:1.0 for the word 'mediocrity' means\n",
        "We are 7.7 times more likely to see 'mediocrity' in documents classified"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "with a negative review\n",
        "\n",
        "This is not suprising since there is a negative\n",
        "connotation associated with a movie or performance that is average"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "A pos/neg value of 7.7:1.0 for the word 'hugo' means\n",
        "we are 7.7 times more likely to see 'hugo' in documents classified\n",
        "with a positive review\n",
        "\n",
        "This is  also not suprising if the rating is referencing\n",
        "the movie 'Hugo' which was in my option excellent\n",
        "\n",
        "A pos/neg value of 6.3:1.0 for the word 'overwhelmed' means\n",
        "we are 6.3 times more likely to see 'overwhelmed' in documents classified"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "with a positive review\n",
        "\n",
        "This is also not suprising since 'overwhelmed' is often followed with joy, with happyness\n",
        "but depending on the context 'overwhelmed' can indicate a negative setiment\n",
        "\n",
        "A pos/neg value of 5.7:1.0 for the word 'dismissed' means\n",
        "we are 5.7 times more likely to see 'dismissed' in documents classified\n",
        "with a positive review\n",
        "\n",
        "This is suprising since 'dismissed' in some contexts\n",
        "has a negative connotation\n",
        "Dismissed from a position, dismissed the story as..\n",
        "\n",
        "A neg/pos value of 3.7:1.0 for the word 'derivative' means\n",
        "we are 3.7 times more likely to see 'derivative' in documents classified\n",
        "with a negative review\n",
        "\n",
        "This is not surprising since the word is found in movie review\n",
        "In this context, the word implies that the film (plot, cinematography), the acting or directing\n",
        "may be very similar to anothers or that it lacks originality\n",
        "In a mathematical context, 'derivative' would be neutral\n",
        "\n",
        "A neg/pos value of 5.0:1.0 for the word 'ugh' means\n",
        "we are 5.0 times more likely to see 'ugh' in documents classified\n",
        "with a negative review\n",
        "\n",
        "This is not surprising at all since 'ugh' says it all\n",
        "\n",
        "For many reviews, without fully knowing the context of the word in the sentence\n",
        "it is very difficult to determine if the classification is correct\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}